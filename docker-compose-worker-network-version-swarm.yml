version: '3.0'  # 使用 Docker Compose 的版本 3.0，適合大部分部署場景

services:
  crawler_twse:  # 定義一個服務，名稱為 crawler_twse
    image: wade52/tibame_crawler:${DOCKER_IMAGE_VERSION}  # 使用的映像檔名稱與標籤（版本）
    hostname: "twse.{{.Task.Slot}}"  # 設定 hostname = twse
    command: pipenv run celery -A crawlerWade52.worker worker --loglevel=info --hostname=%h -Q twse  
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 crawler.worker，設定日誌等級為 info，
    # 使用主機名稱當作 worker 名稱（%h），並將此 worker 加入名為 "twse" 的任務佇列 (queue)
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        # 設定在
        # node label crawler_twse = true 的機器上執行
        constraints: [node.labels.crawler_twse == true]
    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - my_swarm_network  # 將此服務連接到 my_swarm_network 網路

  crawler_tpex:  # 定義一個服務，名稱為 crawler_twse
    image: wade52/tibame_crawler:${DOCKER_IMAGE_VERSION}  # 使用的映像檔名稱與標籤（版本）
    hostname: "tpex.{{.Task.Slot}}"  # 設定 hostname = tpex
    command: pipenv run celery -A crawlerWade52.worker worker --loglevel=info --hostname=%h -Q tpex  
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 crawler.worker，設定日誌等級為 info，
    # 使用主機名稱當作 worker 名稱（%h），並將此 worker 加入名為 "tpex" 的任務佇列 (queue)
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        # 設定在
        # node label crawler_tpex = true 的機器上執行
        constraints: [node.labels.crawler_tpex == true]
    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - my_swarm_network  # 將此服務連接到 my_network 網路

networks:
  my_swarm_network:
    # 加入已經存在的網路
    external: true
